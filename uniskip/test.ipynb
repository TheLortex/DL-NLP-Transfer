{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from model import UniSkip\n",
    "from config import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import nltk\n",
    "\n",
    "from vocab import load_dictionary\n",
    "import gather\n",
    "from sacremoses import MosesDetokenizer\n",
    "detokenizer = MosesDetokenizer()\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:  ['common', 'austin', 'dickens', 'shakespeare', 'wilde', 'songs']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making reverse dictionary\n"
     ]
    }
   ],
   "source": [
    "lr = 3e-4\n",
    "batch_size = 256\n",
    "\n",
    "language = \"english\"\n",
    "categories = list(gather.datasets[language].keys())\n",
    "n_categories = len(categories)\n",
    "print(\"Categories: \", categories)\n",
    "\n",
    "\n",
    "\n",
    "save_loc = \"./saved_models/skip-best-{}\".format(VOCAB_SIZE)\n",
    "mod = UniSkip(n_categories=len(categories))\n",
    "if USE_CUDA:\n",
    "    mod.cuda(CUDA_DEVICE)\n",
    "mod.load_state_dict(torch.load(save_loc))\n",
    "\n",
    "encoder = mod.encoder\n",
    "\n",
    "d = DataLoader(sentences=[''], word_dict=load_dictionary('./dataset/'+language+'/corpus.txt.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing vectors\n",
      "STD: OK\n",
      "Loading text file at /jet/prs/workspace/DL-NLP-Transfer/dataset/english/austin/31100.txt.std\n",
      "Making dictionary for these words\n",
      "Using cached dictionary at /jet/prs/workspace/DL-NLP-Transfer/dataset/english/austin/31100.txt.std.pkl\n",
      "Making reverse dictionary\n",
      "austin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n",
      "100%|██████████| 141/141 [00:14<00:00,  9.92it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences_vectors = {}\n",
    "pre_sentence = {}\n",
    "embedding_size = 1200\n",
    "\n",
    "print(\"Pre-computing vectors\")\n",
    "\n",
    "for c in [\"songs\"]:\n",
    "    cat_index = categories.index(c)\n",
    "    cat_tensor = torch.Tensor([1 if c == cat_index else 0 for c in range(n_categories)]).cuda(CUDA_DEVICE)\n",
    "    \n",
    "    path = gather.get_corpus_location(language, c)\n",
    "    author_sentences = DataLoader(path)\n",
    "    n_sent = len(author_sentences.sentences)\n",
    "    \n",
    "    sentences_vectors[c] = np.empty((n_sent, embedding_size))\n",
    "    pre_sentence[c] = []\n",
    "    print(c)\n",
    "    for i in tqdm.tqdm(range(0, n_sent-batch_size, batch_size)):\n",
    "        batch = []\n",
    "        for j in range(i, min(i + batch_size, n_sent)):\n",
    "            sent = author_sentences.sentences[j]\n",
    "            pre_sentence[c].append(sent)\n",
    "            ind = d.convert_sentence_to_indices(sent)\n",
    "            batch.append(ind)\n",
    "        output, _ = encoder(torch.stack(batch), cat_tensor)\n",
    "        sentences_vectors[c][i:min(i+batch_size, n_sent)] = output.cpu().data.numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(sentences_vectors[\"shakespeare\"], open( \"dataset/\"+language+\"/\"+\"embeddings_shak.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gather\n",
    "import tqdm\n",
    "from scipy.spatial import distance\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def prepare_test(sentence):\n",
    "    return \" \".join(nltk.word_tokenize(sentence))\n",
    "\n",
    "def get_vector(sentence, category_from):\n",
    "    cat_index = categories.index(category_from)\n",
    "    cat_tensor = torch.Tensor([1 if c == cat_index else 0 for c in range(n_categories)]).cuda(CUDA_DEVICE)\n",
    "    \n",
    "    indices = d.convert_sentence_to_indices(sentence)\n",
    "    output, _ = encoder(torch.stack([indices]), cat_tensor)\n",
    "    return output\n",
    "    \n",
    "def get_closest_sentence(sentence, source_author, target_author):\n",
    "    \n",
    "    path = gather.get_corpus_location(language, target_author)\n",
    "    author_sentences = DataLoader(path)\n",
    "    \n",
    "    target_vector = get_vector(prepare_test(sentence), source_author).cpu().data.numpy()\n",
    "    \n",
    "    sentences = sentences_vectors[target_author]\n",
    "    \n",
    "    max_sim = 0\n",
    "    \n",
    "    for i, vector in tqdm.tqdm(enumerate(sentences)):\n",
    "        sim = 1 - distance.cosine(vector, target_vector)\n",
    "\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            max_sent = pre_sentence[target_author][i]\n",
    "    return max_sent, max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"This is not what I expected.\"\n",
    "target_author = \"austin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n",
      "1710it [00:00, 17097.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STD: OK\n",
      "Loading text file at /jet/prs/workspace/DL-NLP-Transfer/dataset/english/austin/31100.txt.std\n",
      "Making dictionary for these words\n",
      "Using cached dictionary at /jet/prs/workspace/DL-NLP-Transfer/dataset/english/austin/31100.txt.std.pkl\n",
      "Making reverse dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34457it [00:01, 18589.07it/s]/jet/var/python/lib/python3.6/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "36346it [00:02, 18092.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.389588867141\n",
      "This is what the world does.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res, max_sim = get_closest_sentence(test_sentence, \"songs\", target_author)\n",
    "print(max_sim)\n",
    "print(detokenizer.detokenize(res.split(\" \"), return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    }
   ],
   "source": [
    "source_author = \"common\"\n",
    "sentence = \"Hi, I'm happy.\"\n",
    "print(get_vector(prepare_test(sentence), source_author).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
