{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from model import UniSkip\n",
    "from config import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import nltk\n",
    "\n",
    "from vocab import load_dictionary\n",
    "import gather\n",
    "from sacremoses import MosesDetokenizer\n",
    "detokenizer = MosesDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:  ['common', 'austin', 'dickens', 'shakespeare', 'wilde', 'songs']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making reverse dictionary\n"
     ]
    }
   ],
   "source": [
    "lr = 3e-4\n",
    "\n",
    "language = \"english\"\n",
    "categories = list(gather.datasets[language].keys())\n",
    "n_categories = len(categories)\n",
    "print(\"Categories: \", categories)\n",
    "\n",
    "\n",
    "\n",
    "save_loc = \"./saved_models/skip-best-{}\".format(VOCAB_SIZE)\n",
    "mod = UniSkip(n_categories=len(categories))\n",
    "if USE_CUDA:\n",
    "    mod.cuda(CUDA_DEVICE)\n",
    "mod.load_state_dict(torch.load(save_loc))\n",
    "\n",
    "encoder = mod.encoder\n",
    "\n",
    "d = DataLoader(sentences=[''], word_dict=load_dictionary('./dataset/'+language+'/corpus.txt.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gather\n",
    "import tqdm\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def prepare_test(sentence):\n",
    "    return \" \".join(nltk.word_tokenize(sentence))\n",
    "\n",
    "def get_vector(sentence, category_from):\n",
    "    cat_index = categories.index(category_from)\n",
    "    cat_tensor = torch.Tensor([1 if c == cat_index else 0 for c in range(n_categories)]).cuda(CUDA_DEVICE)\n",
    "    \n",
    "    indices = d.convert_sentence_to_indices(sentence)\n",
    "    output, _ = encoder(torch.stack([indices]), cat_tensor)\n",
    "    return output\n",
    "    \n",
    "def get_closest_sentence(sentence, source_author, target_author):\n",
    "    cat_index = categories.index(target_author)\n",
    "    cat_tensor = torch.Tensor([1 if c == cat_index else 0 for c in range(n_categories)]).cuda(CUDA_DEVICE)\n",
    "    \n",
    "    \n",
    "    path = gather.get_corpus_location(language, target_author)\n",
    "    author_sentences = DataLoader(path)\n",
    "    \n",
    "    target_vector = get_vector(prepare_test(sentence), source_author)\n",
    "    \n",
    "    batch_size = 256\n",
    "    max_sim = 0\n",
    "    max_sent = []\n",
    "    n_sent = len(author_sentences.sentences)\n",
    "    \n",
    "    for i in tqdm.tqdm(range(0, n_sent-batch_size, batch_size)):\n",
    "        batch = []\n",
    "        for j in range(i, min(i + batch_size, n_sent)):\n",
    "            sent = author_sentences.sentences[j]\n",
    "            ind = d.convert_sentence_to_indices(sent)\n",
    "            batch.append(ind)\n",
    "        output, _ = encoder(torch.stack(batch), cat_tensor)\n",
    "        \n",
    "        sim = F.cosine_similarity(output, target_vector)\n",
    "        val, ind = sim.max(0)\n",
    "\n",
    "        if val > max_sim:\n",
    "            max_sim = val\n",
    "            max_sent = batch[ind]\n",
    "    return max_sent, max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"This is odd.\"\n",
    "target_author = \"wilde\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n",
      "  4%|▎         | 1/27 [00:00<00:03,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STD: OK\n",
      "Loading text file at /jet/prs/workspace/DL-NLP-Transfer/dataset/english/wilde/cu31924103377051_djvu.txt.std\n",
      "Making dictionary for these words\n",
      "Using cached dictionary at /jet/prs/workspace/DL-NLP-Transfer/dataset/english/wilde/cu31924103377051_djvu.txt.std.pkl\n",
      "Making reverse dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:02<00:00, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 145   14 3180 1272    3    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0] tensor(0.6097, device='cuda:0', grad_fn=<MaxBackward0>)\n",
      "This is Uncle Jack.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res, max_sim = get_closest_sentence(test_sentence, \"wilde\", target_author)\n",
    "print(res.cpu().data.numpy(), max_sim)\n",
    "sent = [x for x in res if x != 0]\n",
    "sent = d.convert_indices_to_sentences(sent)\n",
    "\n",
    "\n",
    "print(detokenizer.detokenize(sent.split(\" \"), return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.9509e-01, -8.9650e-02, -1.1045e-01,  ..., -3.3493e-02,\n",
      "         -2.6543e-03, -1.3911e-01]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    }
   ],
   "source": [
    "source_author = \"common\"\n",
    "sentence = \"Hi, I'm happy.\"\n",
    "print(get_vector(prepare_test(sentence), source_author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
