{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /jet/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from model import FillThoughts\n",
    "from config import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import nltk\n",
    "\n",
    "from vocab import load_dictionary\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import gather\n",
    "from sacremoses import MosesDetokenizer\n",
    "detokenizer = MosesDetokenizer()\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making reverse dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    }
   ],
   "source": [
    "d = DataLoader(sentences=[''], word_dict=load_dictionary('../dataset/english/all.tokenized.txt.pkl'))\n",
    "save_loc = \"./saved_models/skip-best-0.0003-20000\"\n",
    "model = FillThoughts()\n",
    "if USE_CUDA:\n",
    "    model.cuda(CUDA_DEVICE)\n",
    "model.load_state_dict(torch.load(save_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(sent):\n",
    "    return \" \".join(nltk.word_tokenize(sent))\n",
    "\n",
    "def infer(before, after, hint=None):\n",
    "    before = std(before)\n",
    "    after = std(after)\n",
    "    ind_before = d.convert_sentence_to_indices(before).unsqueeze(dim=0)\n",
    "    ind_after = d.convert_sentence_to_indices(after).unsqueeze(dim=0)\n",
    "    if hint is None:\n",
    "        input_tensor = torch.cat([ind_before, ind_before, ind_after])\n",
    "    else:\n",
    "        hint = std(hint)\n",
    "        ind_hint = d.convert_sentence_to_indices(hint).unsqueeze(dim=0)\n",
    "        input_tensor = torch.cat([ind_before, ind_hint, ind_after])\n",
    "    thoughts, emb = model.encoder(input_tensor)\n",
    "    if hint is None:\n",
    "        pred = model.decoder(thoughts, None, model.encoder.word2embd)\n",
    "    else:\n",
    "        pred = model.decoder(thoughts, emb)\n",
    "        \n",
    "    _, pred = pred.max(dim=2)\n",
    "    res = d.convert_indices_to_sentences(pred[0])\n",
    "    return detokenizer.detokenize(res.split(\" \"), return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK like his his EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS EOS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    }
   ],
   "source": [
    "# I shoved the pages under my shirt before I made it through the last door .\n",
    "# The village was crowded with elves , oblivious to my horror \n",
    "# The protection spell must have only alerted council .\n",
    "\n",
    "\n",
    "print(infer(\"You just met him in the morning.\",\"Stared at.\",\"Not even met.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing vectors\n",
      "Loading text file at ../dataset/english/all.tokenized.txt\n",
      "Making dictionary for these words\n",
      "Using cached dictionary at ../dataset/english/all.tokenized.txt.pkl"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3906 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making reverse dictionary\n",
      "2472079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n",
      " 47%|████▋     | 1839/3906 [05:28<06:09,  5.60it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "import tqdm\n",
    "sentences_vectors = None\n",
    "pre_sentence = None\n",
    "embedding_size = 1200\n",
    "batch_size = 256\n",
    "\n",
    "print(\"Pre-computing vectors\")\n",
    "path = \"../dataset/english/all.tokenized.txt\"\n",
    "author_sentences = DataLoader(path)\n",
    "n_sent = len(author_sentences.sentences)\n",
    "print(n_sent)\n",
    "n_sent = 1000*1000\n",
    "sentences_vectors = np.empty((n_sent, embedding_size))\n",
    "pre_sentence = []\n",
    "\n",
    "for i in tqdm.tqdm(range(0, n_sent-batch_size, batch_size)):\n",
    "    batch = []\n",
    "    for j in range(i, min(i + batch_size, n_sent)):\n",
    "        sent = author_sentences.sentences[j]\n",
    "        pre_sentence.append(sent)\n",
    "        ind = d.convert_sentence_to_indices(sent)\n",
    "        batch.append(ind)\n",
    "    output, _ = model.encoder(torch.stack(batch))\n",
    "    sentences_vectors[i:min(i+batch_size, n_sent)] = output.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gather\n",
    "import tqdm\n",
    "from scipy.spatial import distance\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def prepare_test(sentence):\n",
    "    return \" \".join(nltk.word_tokenize(sentence))\n",
    "\n",
    "def get_vector(sentence):\n",
    "    indices = d.convert_sentence_to_indices(sentence)\n",
    "    output, _ = model.encoder(torch.stack([indices]))\n",
    "    return output\n",
    "    \n",
    "def get_closest_sentence(sentence):\n",
    "    target_vector = get_vector(prepare_test(sentence)).cpu().data.numpy()\n",
    "    sentences = sentences_vectors\n",
    "    \n",
    "    max_sim = 0\n",
    "    \n",
    "    for i, vector in tqdm.tqdm(enumerate(sentences)):\n",
    "        sim = 1 - distance.cosine(vector, target_vector)\n",
    "\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            max_sent = pre_sentence[i]\n",
    "    return max_sent, max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_closest_sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7f916fcdffc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_closest_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I'm from France.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_closest_sentence' is not defined"
     ]
    }
   ],
   "source": [
    "ms, mss = get_closest_sentence(\"I'm from France.\")\n",
    "print(mss)\n",
    "print(detokenizer.detokenize(ms.split(\" \"), return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
