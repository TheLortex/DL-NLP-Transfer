{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from model import UniSkip\n",
    "from config import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text file at ./dataset/english/corpus.txt\n",
      "Making dictionary for these words\n",
      "Using cached dictionary at ./dataset/english/corpus.txt.pkl\n",
      "Making reverse dictionary\n"
     ]
    }
   ],
   "source": [
    "language = \"english\"\n",
    "d = DataLoader(\"./dataset/\"+language+\"/corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = UniSkip()\n",
    "if USE_CUDA:\n",
    "    mod.cuda(CUDA_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "optimizer = torch.optim.Adam(params=mod.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_trail = []\n",
    "last_best_loss = None\n",
    "\n",
    "def debug(i, loss, prev, nex, prev_pred, next_pred):\n",
    "    global loss_trail\n",
    "    global last_best_loss\n",
    "    global current_time\n",
    "\n",
    "    this_loss = loss.item()\n",
    "    loss_trail.append(this_loss)\n",
    "    loss_trail = loss_trail[-20:]\n",
    "    \n",
    "    try:\n",
    "        trail_loss = sum(loss_trail)/len(loss_trail)\n",
    "        if last_best_loss is None or last_best_loss > trail_loss:\n",
    "            print(\"Loss improved from {} to {}\".format(last_best_loss, trail_loss))\n",
    "            \n",
    "            save_loc = \"./saved_models/skip-best\".format(lr, VOCAB_SIZE)\n",
    "            print(\"saving model at {}\".format(save_loc))\n",
    "            torch.save(mod.state_dict(), save_loc)\n",
    "            \n",
    "            last_best_loss = trail_loss\n",
    "    except Exception as e:\n",
    "       print(\"Couldn't save model because {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Loss improved from None to 19.80767059326172\n",
      "saving model at ./saved_models/skip-best\n",
      "Couldn't save model because [Errno 2] No such file or directory: './saved_models/skip-best'\n",
      "Loss improved from None to 18.183279037475586\n",
      "saving model at ./saved_models/skip-best\n",
      "Couldn't save model because [Errno 2] No such file or directory: './saved_models/skip-best'\n",
      "Loss improved from None to 17.534679412841797\n",
      "saving model at ./saved_models/skip-best\n",
      "Couldn't save model because [Errno 2] No such file or directory: './saved_models/skip-best'\n",
      "Loss improved from None to 17.203145027160645\n",
      "saving model at ./saved_models/skip-best\n",
      "Couldn't save model because [Errno 2] No such file or directory: './saved_models/skip-best'\n",
      "Loss improved from None to 16.998593139648438\n",
      "saving model at ./saved_models/skip-best\n",
      "Couldn't save model because [Errno 2] No such file or directory: './saved_models/skip-best'\n",
      "Loss improved from None to 16.860496520996094\n",
      "saving model at ./saved_models/skip-best\n",
      "Couldn't save model because [Errno 2] No such file or directory: './saved_models/skip-best'\n",
      "Loss improved from None to 16.76295961652483\n",
      "saving model at ./saved_models/skip-best\n",
      "Couldn't save model because [Errno 2] No such file or directory: './saved_models/skip-best'\n",
      "Loss improved from None to 16.6909019947052\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.6909019947052 to 16.63531600104438\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.63531600104438 to 16.58867664337158\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.58867664337158 to 16.54998848655007\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.54998848655007 to 16.51771116256714\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.51771116256714 to 16.49198341369629\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.49198341369629 to 16.468789918082102\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.468789918082102 to 16.450419108072918\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.450419108072918 to 16.434333086013794\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.434333086013794 to 16.41889830196605\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.41889830196605 to 16.4057527118259\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.4057527118259 to 16.394535968178197\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.394535968178197 to 16.38443593978882\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.38443593978882 to 16.20341291427612\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.20341291427612 to 16.184563159942627\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.184563159942627 to 16.18178024291992\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.18178024291992 to 16.179393672943114\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.179393672943114 to 16.178673839569093\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.178673839569093 to 16.178402042388917\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.178402042388917 to 16.177369689941408\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.177369689941408 to 16.17639102935791\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.17639102935791 to 16.17623405456543\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.17623405456543 to 16.1761043548584\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.1761043548584 to 16.175379848480226\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.175379848480226 to 16.174121379852295\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.174121379852295 to 16.174017906188965\n",
      "saving model at ./saved_models/skip-best\n",
      "Loss improved from 16.174017906188965 to 16.17240285873413\n",
      "saving model at ./saved_models/skip-best\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a6e5f9a42384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_pred\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projets/DLDIY/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences, lengths)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# mask the predictions, so that loss for beyond-EOS word predictions is cancelled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mprev_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mnext_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mmasked_prev_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_pred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprev_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projets/DLDIY/model.py\u001b[0m in \u001b[0;36mcreate_mask\u001b[0;34m(self, var, lengths)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "# a million iterations\n",
    "for i in range(0, 1000000):\n",
    "    sentences, lengths = d.fetch_batch(8 * 8)\n",
    "\n",
    "    loss, prev, nex, prev_pred, next_pred  = mod(sentences, lengths)\n",
    "    writer.add_scalar('data/loss', loss, i)\n",
    "    \n",
    "\n",
    "    if i % 30 == 0:\n",
    "        str_prev = d.convert_indices_to_sentences(prev)\n",
    "        str_prev_pred = d.convert_indices_to_sentences(prev_pred)\n",
    "        str_next = d.convert_indices_to_sentences(nex)\n",
    "        str_next_pred = d.convert_indices_to_sentences(next_pred)\n",
    "        writer.add_text('Prev', str_prev + ' | ' + str_prev_pred, i)\n",
    "        writer.add_text('Next', str_next + ' | ' + str_next_pred, i)\n",
    "        debug(i, loss, prev, nex, prev_pred, next_pred)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
