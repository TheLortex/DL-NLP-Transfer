{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from model import UniSkip\n",
    "from config import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text file at ./dataset/english/corpus.txt\n",
      "Making dictionary for these words\n",
      "Using cached dictionary at ./dataset/english/corpus.txt.pkl\n",
      "Making reverse dictionary\n"
     ]
    }
   ],
   "source": [
    "language = \"english\"\n",
    "d = DataLoader(\"./dataset/\"+language+\"/corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    }
   ],
   "source": [
    "mod = UniSkip()\n",
    "if USE_CUDA:\n",
    "    print(\"USING CUDA\")\n",
    "    mod.cuda(CUDA_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "optimizer = torch.optim.Adam(params=mod.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_trail = []\n",
    "last_best_loss = None\n",
    "start_i = 0\n",
    "\n",
    "def debug(i, loss, prev, nex, prev_pred, next_pred):\n",
    "    global loss_trail\n",
    "    global last_best_loss\n",
    "    global current_time\n",
    "\n",
    "    this_loss = loss.item()\n",
    "    loss_trail.append(this_loss)\n",
    "    loss_trail = loss_trail[-20:]\n",
    "    \n",
    "    try:\n",
    "        trail_loss = sum(loss_trail)/len(loss_trail)\n",
    "        if last_best_loss is None or last_best_loss > trail_loss:\n",
    "            print(\"Loss improved from {} to {}\".format(last_best_loss, trail_loss))\n",
    "            \n",
    "            print(\"saving model at {}\".format(save_loc))\n",
    "            torch.save(mod.state_dict(), save_loc)\n",
    "            torch.save((i, trail_loss), save_loc+\".meta\")\n",
    "            \n",
    "            last_best_loss = trail_loss\n",
    "    except Exception as e:\n",
    "       print(\"Couldn't save model because {}\".format(e))\n",
    "    \n",
    "def get_natural_sentence(res):\n",
    "    sent = [x for x in res if x != 0]\n",
    "    sent = d.convert_indices_to_sentences(sent)\n",
    "\n",
    "    from sacremoses import MosesDetokenizer\n",
    "    detokenizer = MosesDetokenizer()\n",
    "\n",
    "    return detokenizer.detokenize(sent.split(\" \"), return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading last checkpoint: ./saved_models/skip-best-0.0003-20000\n",
      "At iter 46680 | Loss: 8.806217098236084\n"
     ]
    }
   ],
   "source": [
    "reload_last_checkpoint = True\n",
    "\n",
    "save_loc = \"./saved_models/skip-best-{}-{}\".format(lr, VOCAB_SIZE)\n",
    "    \n",
    "if reload_last_checkpoint and os.path.exists(save_loc):\n",
    "    print(\"Loading last checkpoint: \"+save_loc)\n",
    "    mod.load_state_dict(torch.load(save_loc))\n",
    "    \n",
    "    start_i, last_best_loss = torch.load(save_loc+\".meta\")\n",
    "    print(\"At iter \"+str(start_i)+\" | Loss: \" + str(last_best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46680\n",
      "Loss improved from 8.806217098236084 to 6.513674259185791\n",
      "saving model at ./saved_models/skip-best-0.0003-20000\n",
      "46710\n",
      "46740\n",
      "46770\n",
      "46800\n",
      "46830\n",
      "46860\n",
      "46890\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "# a million iterations\n",
    "for i in range(start_i, 1000000):\n",
    "    sentences, lengths = d.fetch_batch(32 * 8)\n",
    "\n",
    "    loss, prev, nex, prev_pred, next_pred  = mod(sentences, lengths)\n",
    "    writer.add_scalar('data/loss', loss, i)\n",
    "    \n",
    "\n",
    "    if i % 30 == 0:\n",
    "        print(i)\n",
    "        str_prev = get_natural_sentence(prev)\n",
    "        str_prev_pred = get_natural_sentence(prev_pred)\n",
    "        str_next = get_natural_sentence(nex)\n",
    "        str_next_pred = get_natural_sentence(next_pred)\n",
    "        writer.add_text('Prev', str_prev + ' | ' + str_prev_pred, i)\n",
    "        writer.add_text('Next', str_next + ' | ' + str_next_pred, i)\n",
    "        debug(i, loss, prev, nex, prev_pred, next_pred)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85396\n",
      "saving model at ./saved_models/skip-best-0.0003-20000\n"
     ]
    }
   ],
   "source": [
    "print(i)\n",
    "print(\"saving model at {}\".format(save_loc))\n",
    "trail_loss = sum(loss_trail)/len(loss_trail)\n",
    "torch.save(mod.state_dict(), save_loc)\n",
    "torch.save((i, trail_loss), save_loc+\".meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
